## ğŸš¢ Titanic Survival Prediction
This project uses the famous Titanic dataset to predict whether a passenger survived or not, based on features such as age, gender, class, and family relations.
It applies data preprocessing, feature engineering, and machine learning models to achieve accurate predictions.
```
ğŸ“‚ Project Structure
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv      # Training dataset
â”‚   â”œâ”€â”€ test.csv       # Test dataset
â”‚   â””â”€â”€ gender_submission.csv
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Titanic_EDA.ipynb   # Exploratory Data Analysis
â”‚   â””â”€â”€ Model_Training.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ artifacts/              # Saved models, preprocessing objects
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ“Š Dataset
The dataset is provided by Kaggle Titanic Competition.
train.csv â†’ Training data with survival labels
test.csv â†’ Test data without survival labels
gender_submission.csv â†’ Sample submission format

Features:
PassengerId â€“ Unique ID
Pclass â€“ Ticket class (1, 2, 3)
Name â€“ Passengerâ€™s name
Sex â€“ Gender
Age â€“ Age in years
SibSp â€“ # of siblings/spouses aboard
Parch â€“ # of parents/children aboard
Ticket â€“ Ticket number
Fare â€“ Passenger fare
Cabin â€“ Cabin number
Embarked â€“ Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)
Target: Survived (0 = No, 1 = Yes)

âš™ï¸ Installation
Clone the repo: git clone https://github.com/your-username/titanic-survival-prediction.git
cd titanic-survival-prediction

Install dependencies:
pip install -r requirements.txt

ğŸš€ Usage
Run preprocessing & model training
python src/data_preprocessing.py
python src/model_training.py
Run Jupyter Notebook
jupyter notebook notebooks/Titanic_EDA.ipynb

ğŸ“ˆ Models Implemented
Logistic Regression
Random Forest
XGBoost
Support Vector Machine

Evaluation Metrics:
Accuracy
Precision, Recall, F1-Score
Confusion Matrix

ğŸ“Š Results
Model	Accuracy
Logistic Regression	78%
Random Forest	82%
XGBoost	84%
SVM	80%
âœ… Best Performing Model: XGBoost (84% Accuracy)

ğŸ–¥ï¸ Dashboard (Optional)
If you deploy with Streamlit/Flask, you can add an interactive dashboard to test predictions. Example:

streamlit run app.py
```
ğŸ‘¨â€ğŸ’» Author
Jyothi Swaroop GitHub: jyothiswaroop-09 Email: swaroop.motupalii@gmail.com

